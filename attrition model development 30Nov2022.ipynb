{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n",
    "from project_lib import Project\n",
    "project = Project(spark.sparkContext, 'a2a29465-a371-4b43-b30a-1ecd79492c0f', 'p-360fa5c487a1377ce74f8ef5f9af1d6d0e3744c9')\n",
    "pc = project.project_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Insert project token, API key, and region\n",
    "\n",
    "<img src=\"https://cp4d-outcomes.techzone.ibm.com/img/data-fabric-lab/trusted-ai/project_token_for_notebook.png\" width=400 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the **three vertical dots** icon above and select **Insert project token** to provide this notebook API access to your project.\n",
    "\n",
    "The code inserted above will have a line that looks like this:\n",
    "\n",
    "`project = Project(spark.sparkContext, 'xxxxxxxx-xxx-xxxx-xxxx-xxxxxxxxxx', 'p-xxxxxxxxxxxxxxxxxx')`\n",
    "\n",
    "The first variable value from the cell above (the one that does **not** begin with `p-`) is your project ID, and should be pasted into the cell below as the value for `PROJECT_ID`. The API key you created earlier in the lab should be pasted into the cell below as the value for `API_KEY`.\n",
    "\n",
    "The project ID value is also available on the **Manage** tab of your project, in the **General** section.\n",
    "\n",
    "The **LOCATION** value below will depend on where you provisioned your services. According to the [WML Client documentation](https://ibm-wml-api-pyclient.mybluemix.net/#authentication), valid values for **LOCATION** are:\n",
    "* Dallas: https://us-south.ml.cloud.ibm.com\n",
    "* London: https://eu-gb.ml.cloud.ibm.com\n",
    "* Frankfurt: https://eu-de.ml.cloud.ibm.com\n",
    "* Tokyo: https://jp-tok.ml.cloud.ibm.com\n",
    "\n",
    "Run the cell above, and continue running cells individually until you reach step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'V20GxKBJhE770COJBUSgto2R197lKy25OKR6n5o97_VD'\n",
    "PROJECT_ID = 'a2a29465-a371-4b43-b30a-1ecd79492c0f'\n",
    "LOCATION = 'https://us-south.ml.cloud.ibm.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"p-\" in PROJECT_ID:\n",
    "    raise Exception(\"You have not correctly set the value for your PROJECT_ID. The value beginning with 'p-' is your project access \\\n",
    "    token. Please copy the value of the project_id into the previous cell and re-run it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model you will create in this notebook uses the scikit-learn framework. The `sklearn` package is available by default in Watson Studio Python environments, and does not need to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell uses the API key and location variables defined above to authenticate with your Watson Machine Learning service. An error in this cell likely means that you do not have access to a WML service, or that the API key or location provided above is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "wml_credentials = {\n",
    "    \"apikey\": API_KEY,\n",
    "    \"url\": LOCATION\n",
    "}\n",
    "\n",
    "wml_client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">2. !!--STOP--!! Insert data to code below</span>\n",
    "\n",
    "Place your cursor in the empty code cell below. Then click the **Find and add data** icon in the upper right corner of the screen -- it looks like a grid of ones and zeroes.\n",
    "\n",
    "<img src=\"https://cp4d-outcomes.techzone.ibm.com/img/data-fabric-lab/trusted-ai/find_and_add_data.png\" width=400 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the **Files** tab in the window that opens, locate the *modeling_records_2022.csv* file from the list of files beneath the drag and drop area, and use the **Insert to code** dropdown beneath it to select **pandas DataFrame**. A code block is automatically inserted into the empty cell that will import your data into a dataframe. Like the `sklearn` package, `pandas` is automatically provided in Watson Studio Python environments.\n",
    "\n",
    "## <span style=\"color:red\">IMPORTANT: replace all instances of `df_data_x` with `df_data_1` in the code</span>\n",
    "\n",
    "The automated dataframe will likely use the `df_data_3` variable to hold the data. Update the last two lines of code to import data into the `df_data_1` variable for the rest of the notebook to work correctly. The last lines of your cell should look like this:\n",
    "\n",
    "<img src=\"https://cp4d-outcomes.techzone.ibm.com/img/data-fabric-lab/trusted-ai/dataframe_insert.png\" width=300 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the inserted code cell below. If you have correctly imported the data, you will see a table populated with employee data. Continue running cells individually until you reach step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION_CODE</th>\n",
       "      <th>DEPARTMENT_CODE</th>\n",
       "      <th>DAYS_WITH_COMPANY</th>\n",
       "      <th>COMMUTE_TIME</th>\n",
       "      <th>AGE_BEGIN_PERIOD</th>\n",
       "      <th>GENDER_CODE</th>\n",
       "      <th>ATTRITION</th>\n",
       "      <th>PERIOD_TOTAL_DAYS</th>\n",
       "      <th>STARTING_SALARY</th>\n",
       "      <th>ENDING_SALARY</th>\n",
       "      <th>...</th>\n",
       "      <th>VACATION_DAYS_TAKEN</th>\n",
       "      <th>SICK_DAYS_TAKEN</th>\n",
       "      <th>PROMOTIONS</th>\n",
       "      <th>NB_MANAGERS</th>\n",
       "      <th>DAYS_IN_POSITION</th>\n",
       "      <th>DAYS_SINCE_LAST_RAISE</th>\n",
       "      <th>RANKING_CODE</th>\n",
       "      <th>OVERTIME</th>\n",
       "      <th>DBLOVERTIME</th>\n",
       "      <th>TRAVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>1825</td>\n",
       "      <td>29</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>159230.77</td>\n",
       "      <td>161538.46</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1825</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>2615</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>181153.85</td>\n",
       "      <td>183846.15</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2615</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300</td>\n",
       "      <td>320</td>\n",
       "      <td>1609</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>129692.31</td>\n",
       "      <td>132923.08</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1609</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1300</td>\n",
       "      <td>320</td>\n",
       "      <td>2035</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>146769.23</td>\n",
       "      <td>150461.54</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2035</td>\n",
       "      <td>210</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400</td>\n",
       "      <td>380</td>\n",
       "      <td>1885</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>146769.23</td>\n",
       "      <td>150461.54</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1885</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   POSITION_CODE  DEPARTMENT_CODE  DAYS_WITH_COMPANY  COMMUTE_TIME  \\\n",
       "0           1200              200               1825            29   \n",
       "1           1200              200               2615             0   \n",
       "2           1300              320               1609            30   \n",
       "3           1300              320               2035            13   \n",
       "4           1400              380               1885            31   \n",
       "\n",
       "   AGE_BEGIN_PERIOD  GENDER_CODE  ATTRITION  PERIOD_TOTAL_DAYS  \\\n",
       "0                55            0          0                330   \n",
       "1                49            0          0                180   \n",
       "2                44            1          0                330   \n",
       "3                45            0          0                330   \n",
       "4                44            0          0                330   \n",
       "\n",
       "   STARTING_SALARY  ENDING_SALARY  ...  VACATION_DAYS_TAKEN  SICK_DAYS_TAKEN  \\\n",
       "0        159230.77      161538.46  ...                   28             10.5   \n",
       "1        181153.85      183846.15  ...                   15              4.0   \n",
       "2        129692.31      132923.08  ...                   20             15.0   \n",
       "3        146769.23      150461.54  ...                   28              8.0   \n",
       "4        146769.23      150461.54  ...                   26             11.5   \n",
       "\n",
       "   PROMOTIONS  NB_MANAGERS  DAYS_IN_POSITION  DAYS_SINCE_LAST_RAISE  \\\n",
       "0           0            1              1825                      0   \n",
       "1           0            1              2615                     60   \n",
       "2           0            1              1609                    150   \n",
       "3           0            1              2035                    210   \n",
       "4           0            1              1885                     60   \n",
       "\n",
       "   RANKING_CODE  OVERTIME  DBLOVERTIME  TRAVEL  \n",
       "0             3       0.0          0.0       0  \n",
       "1             3       0.0          0.0       0  \n",
       "2             3       0.0          0.0       0  \n",
       "3             3       0.0          0.0       0  \n",
       "4             3       0.0          0.0       0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='hS34jXqg4cO0rmMfwxn-w7X_yX1vMuZVoijkItsXXo6L',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'trustedail3techlab-donotdelete-pr-ivzkukectdytod'\n",
    "object_key = 'modeling_records_2022.csv'\n",
    "\n",
    "body = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df_data_1 = pd.read_csv(body)\n",
    "df_data_1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell splits the training data into the feature columns and the label columns, and then further splits the data further into a training data set and a testing data set. If this cell generates an error, it is likely because you have not imported the data into the `df_data_1` variable as described above. You will need to alter the previous cell to use `df_data_1` and then rerun it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_data_1.drop(['ATTRITION'], axis=1)  # Features\n",
    "y = df_data_1['ATTRITION']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15) # 85% training and 15% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will tell Watson Machine Learning to use the current project to store the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITION_CODE',\n",
       " 'DEPARTMENT_CODE',\n",
       " 'DAYS_WITH_COMPANY',\n",
       " 'COMMUTE_TIME',\n",
       " 'AGE_BEGIN_PERIOD',\n",
       " 'GENDER_CODE',\n",
       " 'PERIOD_TOTAL_DAYS',\n",
       " 'STARTING_SALARY',\n",
       " 'ENDING_SALARY',\n",
       " 'NB_INCREASES',\n",
       " 'BONUS',\n",
       " 'NB_BONUS',\n",
       " 'VACATION_DAYS_TAKEN',\n",
       " 'SICK_DAYS_TAKEN',\n",
       " 'PROMOTIONS',\n",
       " 'NB_MANAGERS',\n",
       " 'DAYS_IN_POSITION',\n",
       " 'DAYS_SINCE_LAST_RAISE',\n",
       " 'RANKING_CODE',\n",
       " 'OVERTIME',\n",
       " 'DBLOVERTIME',\n",
       " 'TRAVEL']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below tells the Watson Machine Learning client to save the models in the current project. If you receive an error here, it is likely because you did not correctly set your project ID at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wml_client.set.default_project(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell provides connection information to the model training data, which will be stored with the model and in FactSheets. You could use the Cloud Object Storage information for this particular project by changing the credentials to match those from above where you inserted the file to code, but for simplicity's sake, you will use a pre-existing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_references = [\n",
    "                {\n",
    "                    \"id\": \"attrition\",\n",
    "                    \"type\": \"container\",\n",
    "                    \"connection\": {},\n",
    "                    \"location\": {\n",
    "                        \"path\": \"modeling_records_2022.csv\"\n",
    "                    },\n",
    "\n",
    "                    #\"type\": \"s3\",\n",
    "                    #\"connection\": {\n",
    "                    #    \"access_key_id\": \"yqcPbWZ0AQPHleHVerrR4Wx5e9pymBdMgydbEra5zCif\",\n",
    "                    #    \"endpoint_url\": \"https://s3.us.cloud-object-storage.appdomain.cloud\",\n",
    "                    #    \"resource_instance_id\": \"crn:v1:bluemix:public:cloud-object-storage:global:a/7d8b3c34272c0980d973d3e40be9e9d2:2883ef10-23f1-4592-8582-2f2ef4973639::\"\n",
    "                    #},\n",
    "                    #\"location\": {\n",
    "                    #    \"bucket\": \"faststartlab-donotdelete-pr-nhfd4jnhlxgpc7\",\n",
    "                    #    \"path\": \"modeling_records_2022.csv\"\n",
    "                    #},\n",
    "                    \"schema\": {\n",
    "                        \"id\": \"training_schema\",\n",
    "                        \"fields\": [\n",
    "                            {\"name\": \"POSITION_CODE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"DEPARTMENT_CODE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"DAYS_WITH_COMPANY\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"COMMUTE_TIME\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"AGE_BEGIN_PERIOD\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"GENDER_CODE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"PERIOD_TOTAL_DAYS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"STARTING_SALARY\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"ENDING_SALARY\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"NB_INCREASES\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"BONUS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"NB_BONUS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"VACATION_DAYS_TAKEN\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"SICK_DAYS_TAKEN\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"PROMOTIONS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"NB_MANAGERS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"DAYS_IN_POSITION\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"DAYS_SINCE_LAST_RAISE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"RANKING_CODE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"OVERTIME\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"DBLOVERTIME\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n",
    "                            {\"name\": \"TRAVEL\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will authenticate with the IBM FactSheet service using credentials you have already supplied and initialize FactSheet monitoring for this model. Note that Python notebooks in Watson Studio have full support for `pip install`, which allows you to add whatever libraries you need to the notebook environment. For example, if you wanted to use Python to parse command line arguments, you could run `!pip install argparse`.\n",
    "\n",
    "If you receive an error related to the project access token, it is likely because you either did not insert the project access token as instructed at the beginning of the notebook, or did not run the cell after it was inserted. You will need to return to the beginning of the notebook, ensure the cell is inserted, and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ibm-aigov-facts-client\n",
      "  Downloading ibm_aigov_facts_client-1.0.28-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 26.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-aigov-facts-client) (1.3.4)\n",
      "Collecting mlflow-skinny==1.28.0\n",
      "  Downloading mlflow_skinny-1.28.0-py3-none-any.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 76.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-aigov-facts-client) (2.26.0)\n",
      "Requirement already satisfied: ibm-cloud-sdk-core>=3.5.2 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-aigov-facts-client) (3.10.1)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "\u001b[K     |████████████████████████████████| 547 kB 73.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-aigov-facts-client) (1.20.3)\n",
      "Collecting timeout-decorator\n",
      "  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (3.19.1)\n",
      "Requirement already satisfied: pytz<2023 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (2021.3)\n",
      "Requirement already satisfied: cloudpickle<3 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (1.6.0)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<5,>=3.7.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (4.8.2)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (5.4.1)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 5.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (8.0.4)\n",
      "Requirement already satisfied: entrypoints<1 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (0.3)\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 74.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging<22 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (21.3)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (2.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (3.2.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (0.8.9)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (1.15.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 937 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.5.3 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-cloud-sdk-core>=3.5.2->ibm-aigov-facts-client) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<5,>=3.7.0->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from packaging<22->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from requests<3.0,>=2.0->ibm-aigov-facts-client) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from requests<3.0,>=2.0->ibm-aigov-facts-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from requests<3.0,>=2.0->ibm-aigov-facts-client) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from requests<3.0,>=2.0->ibm-aigov-facts-client) (1.26.7)\n",
      "Building wheels for collected packages: databricks-cli, timeout-decorator\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.17.3-py3-none-any.whl size=139103 sha256=925cc83e1c03529c46ed69f2314fc65c9f4a7a8179aab97222a00f178c564a98\n",
      "  Stored in directory: /home/spark/shared/.cache/pip/wheels/7b/ef/c5/85718fa9e66dec117e42d8b4d7b8a2e40ebdec17232935615f\n",
      "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5028 sha256=accb102453819e4fa7ac96d23cb9c1ba387d6eed7dfadb60f16ab6b6ca39c270\n",
      "  Stored in directory: /home/spark/shared/.cache/pip/wheels/5d/45/1d/a7d2bf8dfbdecd78983a3d422f2fe860316cfbae3f3b001ea5\n",
      "Successfully built databricks-cli timeout-decorator\n",
      "Installing collected packages: smmap, gitdb, sqlparse, gitpython, databricks-cli, timeout-decorator, mlflow-skinny, docutils, ibm-aigov-facts-client\n",
      "Successfully installed databricks-cli-0.17.3 docutils-0.15.2 gitdb-4.0.10 gitpython-3.1.29 ibm-aigov-facts-client-1.0.28 mlflow-skinny-1.28.0 smmap-5.0.0 sqlparse-0.4.3 timeout-decorator-0.5.0\n",
      "2022/11/30 05:00:16 INFO : Experiment predictive_attrition does not exist, creating new experiment\n",
      "2022/11/30 05:00:16 INFO : Experiment successfully created with ID 1 and name predictive_attrition\n",
      "2022/11/30 05:00:16 INFO : Autolog enabled Successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from ibm_aigov_facts_client import AIGovFactsClient\n",
    "except:\n",
    "    !pip install -U ibm-aigov-facts-client\n",
    "    from ibm_aigov_facts_client import AIGovFactsClient\n",
    "        \n",
    "PROJECT_UID= os.environ['PROJECT_ID']\n",
    "CPD_URL=os.environ['RUNTIME_ENV_APSX_URL'][len('https://api.'):]\n",
    "CONTAINER_ID=PROJECT_ID\n",
    "CONTAINER_TYPE='project'\n",
    "EXPERIMENT_NAME='predictive_attrition'\n",
    "\n",
    "PROJECT_ACCESS_TOKEN=project.project_context.accessToken.replace('Bearer ','')\n",
    "\n",
    "facts_client = AIGovFactsClient(api_key=API_KEY,experiment_name=EXPERIMENT_NAME,container_type=CONTAINER_TYPE,container_id=CONTAINER_ID,set_as_current_experiment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells construct metadata for your model. This will be saved with the model itself and will appear on its FactSheet. If you get errors trying to save the model, they will most likely be from the metadata contained in the model properties, specifically the `TYPE` and `SOFTWARE_SPEC_UID`, which frequently change as Watson Studio adds support for new versions of Python, and removes support for outdated versions. You can get a list of current supported specifications by running `wml_client.software_specifications.list()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields=X_train.columns.tolist()\n",
    "metadata_dict = {'target_col' : 'ATTRITION', 'fields':fields}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Specification ID: 12b83a17-24d8-5082-900f-0ab31fbfd3cb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'attrition challenger - sklearn',\n",
       " 'type': 'scikit-learn_1.0',\n",
       " 'software_spec': '12b83a17-24d8-5082-900f-0ab31fbfd3cb',\n",
       " 'training_data_references': [{'id': 'attrition',\n",
       "   'type': 'container',\n",
       "   'connection': {},\n",
       "   'location': {'path': 'modeling_records_2022.csv'},\n",
       "   'schema': {'id': 'training_schema',\n",
       "    'fields': [{'name': 'POSITION_CODE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'DEPARTMENT_CODE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'DAYS_WITH_COMPANY',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'COMMUTE_TIME',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'AGE_BEGIN_PERIOD',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'GENDER_CODE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'PERIOD_TOTAL_DAYS',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'STARTING_SALARY',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'ENDING_SALARY',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'NB_INCREASES',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'BONUS', 'nullable': True, 'metadata': {}, 'type': 'double'},\n",
       "     {'name': 'NB_BONUS', 'nullable': True, 'metadata': {}, 'type': 'double'},\n",
       "     {'name': 'VACATION_DAYS_TAKEN',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'SICK_DAYS_TAKEN',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'PROMOTIONS',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'NB_MANAGERS',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'DAYS_IN_POSITION',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'DAYS_SINCE_LAST_RAISE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'RANKING_CODE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'OVERTIME', 'nullable': True, 'metadata': {}, 'type': 'double'},\n",
       "     {'name': 'DBLOVERTIME',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'TRAVEL',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'}]}}],\n",
       " 'label_column': 'ATTRITION',\n",
       " 'custom': {'experiment_id': '9b59c4b39dfd48c2abc386563f9866c5',\n",
       "  'experiment_name': 'predictive_attrition'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"runtime-22.1-py3.9\")\n",
    "print(\"Software Specification ID: {}\".format(software_spec_uid))\n",
    "model_props = {\n",
    "    wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(\"attrition challenger - sklearn\"),\n",
    "    wml_client._models.ConfigurationMetaNames.TYPE: \"scikit-learn_1.0\",\n",
    "    wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n",
    "    wml_client._models.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: training_data_references,\n",
    "    wml_client._models.ConfigurationMetaNames.LABEL_FIELD: \"ATTRITION\",\n",
    "    wml_client._models.ConfigurationMetaNames.CUSTOM: metadata_dict\n",
    "}\n",
    "\n",
    "facts_client.export_facts.prepare_model_meta(wml_client=wml_client,meta_props=model_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three cells fit the data the the model using a Random Forest classifier, run predictions on the test data, and then print out the accuracy for how the model did on the test data. Finally, the notebook calculates and displays feature importance. For more information on Random Forest classifiers, see [here](https://www.ibm.com/cloud/learn/random-forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/30 05:00:20 INFO : logging results to factsheet for run_id e3287da02c95472aa3aa93f00b6417ae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_aigov_facts_client.store.autolog.general_payload_store:logging results to factsheet for run_id e3287da02c95472aa3aa93f00b6417ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/30 05:00:21 INFO : Successfully logged results to Factsheet service for run_id e3287da02c95472aa3aa93f00b6417ae under asset_id: d2be6bc2-85fb-45a6-a23c-cd11828ac9ea and project_id : a2a29465-a371-4b43-b30a-1ecd79492c0f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_aigov_facts_client.base_classes.auth:Successfully logged results to Factsheet service for run_id e3287da02c95472aa3aa93f00b6417ae under asset_id: d2be6bc2-85fb-45a6-a23c-cd11828ac9ea and project_id : a2a29465-a371-4b43-b30a-1ecd79492c0f\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMUTE_TIME             0.228825\n",
       "OVERTIME                 0.159387\n",
       "DBLOVERTIME              0.087004\n",
       "DAYS_IN_POSITION         0.055499\n",
       "STARTING_SALARY          0.052594\n",
       "ENDING_SALARY            0.050040\n",
       "DAYS_WITH_COMPANY        0.046151\n",
       "PERIOD_TOTAL_DAYS        0.044675\n",
       "AGE_BEGIN_PERIOD         0.043954\n",
       "DAYS_SINCE_LAST_RAISE    0.042997\n",
       "VACATION_DAYS_TAKEN      0.035166\n",
       "RANKING_CODE             0.033583\n",
       "SICK_DAYS_TAKEN          0.030783\n",
       "BONUS                    0.030751\n",
       "POSITION_CODE            0.028626\n",
       "DEPARTMENT_CODE          0.015183\n",
       "GENDER_CODE              0.005895\n",
       "NB_BONUS                 0.004466\n",
       "NB_INCREASES             0.004420\n",
       "NB_MANAGERS              0.000000\n",
       "PROMOTIONS               0.000000\n",
       "TRAVEL                   0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three cells export data from the model you just created to the FactSheet. The first lists experiments tracked by FactSheets. The second writes the URL and other info on this notebook as custom data to the FactSheet. Note that any data can be written to the FactSheet that might be helpful for model validators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>published</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3287da02c95472aa3aa93f00b6417ae</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>file:///home/spark/shared/mlruns/1/e3287da02c9...</td>\n",
       "      <td>2022-11-30 05:00:17.841000+00:00</td>\n",
       "      <td>2022-11-30 05:00:21.577000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id published  \\\n",
       "0  e3287da02c95472aa3aa93f00b6417ae             1      True   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  file:///home/spark/shared/mlruns/1/e3287da02c9...   \n",
       "\n",
       "                        start_time                         end_time  \n",
       "0 2022-11-30 05:00:17.841000+00:00 2022-11-30 05:00:21.577000+00:00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts_client.runs.list_runs_by_experiment('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/30 05:00:22 INFO : Initiating logging to factsheet for run_id......e3287da02c95472aa3aa93f00b6417ae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_aigov_facts_client.export.export_facts:Initiating logging to factsheet for run_id......e3287da02c95472aa3aa93f00b6417ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/30 05:00:23 INFO : Successfully logged results to Factsheet service for run_id e3287da02c95472aa3aa93f00b6417ae under asset_id: d2be6bc2-85fb-45a6-a23c-cd11828ac9ea and project_id : a2a29465-a371-4b43-b30a-1ecd79492c0f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_aigov_facts_client.base_classes.auth:Successfully logged results to Factsheet service for run_id e3287da02c95472aa3aa93f00b6417ae under asset_id: d2be6bc2-85fb-45a6-a23c-cd11828ac9ea and project_id : a2a29465-a371-4b43-b30a-1ecd79492c0f\n"
     ]
    }
   ],
   "source": [
    "nb_name = \"attrition model creation and deployment\"\n",
    "nb_asset_id = \"tbd\"\n",
    "nb_asset_url = \"https://\" + CPD_URL + \"/analytics/notebooks/v2/\" + nb_asset_id + \"?projectid=\" + PROJECT_UID + \"&context=cpdaas\"\n",
    "\n",
    "latestRunId = facts_client.runs.list_runs_by_experiment('1').sort_values('start_time').iloc[-1]['run_id']\n",
    "facts_client.runs.set_tags(latestRunId, {\"Notebook name\": nb_name, \"Notebook id\": nb_asset_id, \"Notebook URL\" : nb_asset_url})\n",
    "facts_client.export_facts.export_payload(latestRunId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/30 05:00:24 INFO : Initiating logging to factsheet for run_id......e3287da02c95472aa3aa93f00b6417ae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_aigov_facts_client.export.export_facts:Initiating logging to factsheet for run_id......e3287da02c95472aa3aa93f00b6417ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/30 05:00:25 INFO : Successfully logged results to Factsheet service for run_id e3287da02c95472aa3aa93f00b6417ae under asset_id: d2be6bc2-85fb-45a6-a23c-cd11828ac9ea and project_id : a2a29465-a371-4b43-b30a-1ecd79492c0f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_aigov_facts_client.base_classes.auth:Successfully logged results to Factsheet service for run_id e3287da02c95472aa3aa93f00b6417ae under asset_id: d2be6bc2-85fb-45a6-a23c-cd11828ac9ea and project_id : a2a29465-a371-4b43-b30a-1ecd79492c0f\n"
     ]
    }
   ],
   "source": [
    "RUN_ID=facts_client.runs.get_current_run_id()\n",
    "facts_client.export_facts.export_payload(RUN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the model is stored to the project with all of the metadata defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing model...\n",
      "Done\n",
      "Model ID: c1ffac5e-8a2e-43db-9305-32549caec122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ibm_aigov_facts_client.store.autolog.spark_payload_store:logging results to factsheet for run_id 37d294878159474aa0296df76913ab16\n",
      "INFO:ibm_aigov_facts_client.base_classes.auth:Successfully logged results to Factsheet service for run_id 37d294878159474aa0296df76913ab16 under asset_id: d2be6bc2-85fb-45a6-a23c-cd11828ac9ea and project_id : a2a29465-a371-4b43-b30a-1ecd79492c0f\n"
     ]
    }
   ],
   "source": [
    "print(\"Storing model...\")\n",
    "published_model_details = wml_client.repository.store_model(\n",
    "    model=clf, \n",
    "    meta_props=model_props,\n",
    "    training_target=['ATTRITION'],\n",
    "    training_data=X)\n",
    "model_uid = wml_client.repository.get_model_id(published_model_details)\n",
    "\n",
    "print(\"Done\")\n",
    "print(\"Model ID: {}\".format(model_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the notebook uses Apache Spark to create a second model. Because you specified a Spark environment when you created this notebook, the `pyspark` runtime will be available without needing to be installed via `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "except:\n",
    "    print('Error: Spark runtime is missing. If you are using Watson Studio change the notebook runtime to Spark by clicking \\\n",
    "    the Vew notebook info button above (the lowercase i in a circle). Click on the Environment tab and use the Environment \\\n",
    "    definition dropdown to select an environment with Spark and Python.')\n",
    "    raise\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">3. !!--STOP--!! Insert data to code below</span>\n",
    "\n",
    "Place your cursor in the empty code cell below. Then click the **Find and add data** icon in the upper right corner of the screen like you did in step 2. Locate the *modeling_records_2022.csv* file, click its associated **Insert to code** dropdown, and select **SparkSession DataFrame**.\n",
    "\n",
    "## <span style=\"color:red\">IMPORTANT: replace all instances of `df_data_x` with `df_data_2` in the code</span>\n",
    "\n",
    "The automated dataframe will likely use the `df_data_3` variable to hold the data. Update the last two lines of code to import data into the `df_data_2` variable for the rest of the notebook to work correctly. The last lines of your cell should look like this:\n",
    "\n",
    "<img src=\"https://cp4d-outcomes.techzone.ibm.com/img/data-fabric-lab/trusted-ai/dataframe_insert_2.png\" width=700 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the inserted code cell below. If you have correctly imported the data, you will see a table populated with employee data. The remainder of the notebook is very similar to the training of the sklearn model. It will enable FactSheets for the second model, train a Spark Gradient Boost Classifier, and then save that model to the project. You may run the rest of the notebook to its conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(POSITION_CODE='1200', DEPARTMENT_CODE='200', DAYS_WITH_COMPANY='1825', COMMUTE_TIME='29', AGE_BEGIN_PERIOD='55', GENDER_CODE='0', ATTRITION='0', PERIOD_TOTAL_DAYS='330', STARTING_SALARY='159230.77', ENDING_SALARY='161538.46', NB_INCREASES='1', BONUS='0', NB_BONUS='0', VACATION_DAYS_TAKEN='28', SICK_DAYS_TAKEN='10.5', PROMOTIONS='0', NB_MANAGERS='1', DAYS_IN_POSITION='1825', DAYS_SINCE_LAST_RAISE='0', RANKING_CODE='3', OVERTIME='0', DBLOVERTIME='0', TRAVEL='0'),\n",
       " Row(POSITION_CODE='1200', DEPARTMENT_CODE='200', DAYS_WITH_COMPANY='2615', COMMUTE_TIME='0', AGE_BEGIN_PERIOD='49', GENDER_CODE='0', ATTRITION='0', PERIOD_TOTAL_DAYS='180', STARTING_SALARY='181153.85', ENDING_SALARY='183846.15', NB_INCREASES='1', BONUS='0', NB_BONUS='0', VACATION_DAYS_TAKEN='15', SICK_DAYS_TAKEN='4', PROMOTIONS='0', NB_MANAGERS='1', DAYS_IN_POSITION='2615', DAYS_SINCE_LAST_RAISE='60', RANKING_CODE='3', OVERTIME='0', DBLOVERTIME='0', TRAVEL='0'),\n",
       " Row(POSITION_CODE='1300', DEPARTMENT_CODE='320', DAYS_WITH_COMPANY='1609', COMMUTE_TIME='30', AGE_BEGIN_PERIOD='44', GENDER_CODE='1', ATTRITION='0', PERIOD_TOTAL_DAYS='330', STARTING_SALARY='129692.31', ENDING_SALARY='132923.08', NB_INCREASES='1', BONUS='0', NB_BONUS='0', VACATION_DAYS_TAKEN='20', SICK_DAYS_TAKEN='15', PROMOTIONS='0', NB_MANAGERS='1', DAYS_IN_POSITION='1609', DAYS_SINCE_LAST_RAISE='150', RANKING_CODE='3', OVERTIME='0', DBLOVERTIME='0', TRAVEL='0'),\n",
       " Row(POSITION_CODE='1300', DEPARTMENT_CODE='320', DAYS_WITH_COMPANY='2035', COMMUTE_TIME='13', AGE_BEGIN_PERIOD='45', GENDER_CODE='0', ATTRITION='0', PERIOD_TOTAL_DAYS='330', STARTING_SALARY='146769.23', ENDING_SALARY='150461.54', NB_INCREASES='1', BONUS='0', NB_BONUS='0', VACATION_DAYS_TAKEN='28', SICK_DAYS_TAKEN='8', PROMOTIONS='0', NB_MANAGERS='1', DAYS_IN_POSITION='2035', DAYS_SINCE_LAST_RAISE='210', RANKING_CODE='3', OVERTIME='0', DBLOVERTIME='0', TRAVEL='0'),\n",
       " Row(POSITION_CODE='1400', DEPARTMENT_CODE='380', DAYS_WITH_COMPANY='1885', COMMUTE_TIME='31', AGE_BEGIN_PERIOD='44', GENDER_CODE='0', ATTRITION='0', PERIOD_TOTAL_DAYS='330', STARTING_SALARY='146769.23', ENDING_SALARY='150461.54', NB_INCREASES='1', BONUS='0', NB_BONUS='0', VACATION_DAYS_TAKEN='26', SICK_DAYS_TAKEN='11.5', PROMOTIONS='0', NB_MANAGERS='1', DAYS_IN_POSITION='1885', DAYS_SINCE_LAST_RAISE='60', RANKING_CODE='3', OVERTIME='0', DBLOVERTIME='0', TRAVEL='0')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import ibmos2spark, os\n",
    "# @hidden_cell\n",
    "metadata = {\n",
    "    'endpoint': 'https://s3.private.us.cloud-object-storage.appdomain.cloud',\n",
    "    'service_id': 'iam-ServiceId-5e082bf0-eb96-485e-a8d2-7b2fdee746f5',\n",
    "    'iam_service_endpoint': 'https://iam.cloud.ibm.com/oidc/token',\n",
    "    'api_key': 'hS34jXqg4cO0rmMfwxn-w7X_yX1vMuZVoijkItsXXo6L'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_f9043eb056184e3eb6fc28c38e5f9558_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, metadata, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_data_2 = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(cos.url('modeling_records_2022.csv', 'trustedail3techlab-donotdelete-pr-ivzkukectdytod'))\n",
    "df_data_2.take(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the `sklearn` model, you need to specify metadata for the spark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Specification ID: 20047f72-0a98-58c7-9ff5-a77b012eb8f5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'attrition challenger - spark',\n",
       " 'type': 'mllib_3.2',\n",
       " 'software_spec': '20047f72-0a98-58c7-9ff5-a77b012eb8f5',\n",
       " 'training_data_references': [{'id': 'attrition',\n",
       "   'type': 'container',\n",
       "   'connection': {},\n",
       "   'location': {'path': 'modeling_records_2022.csv'},\n",
       "   'schema': {'id': 'training_schema',\n",
       "    'fields': [{'name': 'POSITION_CODE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'DEPARTMENT_CODE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'DAYS_WITH_COMPANY',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'COMMUTE_TIME',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'AGE_BEGIN_PERIOD',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'GENDER_CODE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'PERIOD_TOTAL_DAYS',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'STARTING_SALARY',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'ENDING_SALARY',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'NB_INCREASES',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'BONUS', 'nullable': True, 'metadata': {}, 'type': 'double'},\n",
       "     {'name': 'NB_BONUS', 'nullable': True, 'metadata': {}, 'type': 'double'},\n",
       "     {'name': 'VACATION_DAYS_TAKEN',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'SICK_DAYS_TAKEN',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'PROMOTIONS',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'NB_MANAGERS',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'DAYS_IN_POSITION',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'DAYS_SINCE_LAST_RAISE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'RANKING_CODE',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'OVERTIME', 'nullable': True, 'metadata': {}, 'type': 'double'},\n",
       "     {'name': 'DBLOVERTIME',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'},\n",
       "     {'name': 'TRAVEL',\n",
       "      'nullable': True,\n",
       "      'metadata': {},\n",
       "      'type': 'double'}]}}],\n",
       " 'label_column': 'ATTRITION',\n",
       " 'custom': {'experiment_id': 'f688bda653404a3e9fb1390a309c236c',\n",
       "  'experiment_name': 'predictive_attrition'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"spark-mllib_3.2\")\n",
    "print(\"Software Specification ID: {}\".format(software_spec_uid))\n",
    "model_props = {\n",
    "    wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(\"attrition challenger - spark\"),\n",
    "    wml_client._models.ConfigurationMetaNames.TYPE: \"mllib_3.2\",\n",
    "    wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n",
    "    wml_client._models.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: training_data_references,\n",
    "    wml_client._models.ConfigurationMetaNames.LABEL_FIELD: \"ATTRITION\"\n",
    "}\n",
    "\n",
    "facts_client.export_facts.prepare_model_meta(wml_client=wml_client,meta_props=model_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second model, you will create a Gradient Boosted Tree classifier. For more information on Gradient Boosting, see [here](https://www.ibm.com/cloud/learn/boosting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(POSITION_CODE=1200.0, DEPARTMENT_CODE=200.0, DAYS_WITH_COMPANY=1825.0, COMMUTE_TIME=29.0, AGE_BEGIN_PERIOD=55.0, GENDER_CODE=0.0, ATTRITION=0, PERIOD_TOTAL_DAYS=330.0, STARTING_SALARY=159230.765625, ENDING_SALARY=161538.453125, NB_INCREASES=1.0, BONUS=0.0, NB_BONUS=0.0, VACATION_DAYS_TAKEN=28.0, SICK_DAYS_TAKEN=10.5, PROMOTIONS=0.0, NB_MANAGERS=1.0, DAYS_IN_POSITION=1825.0, DAYS_SINCE_LAST_RAISE=0.0, RANKING_CODE=3.0, OVERTIME=0.0, DBLOVERTIME=0.0, TRAVEL=0.0),\n",
       " Row(POSITION_CODE=1200.0, DEPARTMENT_CODE=200.0, DAYS_WITH_COMPANY=2615.0, COMMUTE_TIME=0.0, AGE_BEGIN_PERIOD=49.0, GENDER_CODE=0.0, ATTRITION=0, PERIOD_TOTAL_DAYS=180.0, STARTING_SALARY=181153.84375, ENDING_SALARY=183846.15625, NB_INCREASES=1.0, BONUS=0.0, NB_BONUS=0.0, VACATION_DAYS_TAKEN=15.0, SICK_DAYS_TAKEN=4.0, PROMOTIONS=0.0, NB_MANAGERS=1.0, DAYS_IN_POSITION=2615.0, DAYS_SINCE_LAST_RAISE=60.0, RANKING_CODE=3.0, OVERTIME=0.0, DBLOVERTIME=0.0, TRAVEL=0.0),\n",
       " Row(POSITION_CODE=1300.0, DEPARTMENT_CODE=320.0, DAYS_WITH_COMPANY=1609.0, COMMUTE_TIME=30.0, AGE_BEGIN_PERIOD=44.0, GENDER_CODE=1.0, ATTRITION=0, PERIOD_TOTAL_DAYS=330.0, STARTING_SALARY=129692.3125, ENDING_SALARY=132923.078125, NB_INCREASES=1.0, BONUS=0.0, NB_BONUS=0.0, VACATION_DAYS_TAKEN=20.0, SICK_DAYS_TAKEN=15.0, PROMOTIONS=0.0, NB_MANAGERS=1.0, DAYS_IN_POSITION=1609.0, DAYS_SINCE_LAST_RAISE=150.0, RANKING_CODE=3.0, OVERTIME=0.0, DBLOVERTIME=0.0, TRAVEL=0.0),\n",
       " Row(POSITION_CODE=1300.0, DEPARTMENT_CODE=320.0, DAYS_WITH_COMPANY=2035.0, COMMUTE_TIME=13.0, AGE_BEGIN_PERIOD=45.0, GENDER_CODE=0.0, ATTRITION=0, PERIOD_TOTAL_DAYS=330.0, STARTING_SALARY=146769.234375, ENDING_SALARY=150461.546875, NB_INCREASES=1.0, BONUS=0.0, NB_BONUS=0.0, VACATION_DAYS_TAKEN=28.0, SICK_DAYS_TAKEN=8.0, PROMOTIONS=0.0, NB_MANAGERS=1.0, DAYS_IN_POSITION=2035.0, DAYS_SINCE_LAST_RAISE=210.0, RANKING_CODE=3.0, OVERTIME=0.0, DBLOVERTIME=0.0, TRAVEL=0.0),\n",
       " Row(POSITION_CODE=1400.0, DEPARTMENT_CODE=380.0, DAYS_WITH_COMPANY=1885.0, COMMUTE_TIME=31.0, AGE_BEGIN_PERIOD=44.0, GENDER_CODE=0.0, ATTRITION=0, PERIOD_TOTAL_DAYS=330.0, STARTING_SALARY=146769.234375, ENDING_SALARY=150461.546875, NB_INCREASES=1.0, BONUS=0.0, NB_BONUS=0.0, VACATION_DAYS_TAKEN=26.0, SICK_DAYS_TAKEN=11.5, PROMOTIONS=0.0, NB_MANAGERS=1.0, DAYS_IN_POSITION=1885.0, DAYS_SINCE_LAST_RAISE=60.0, RANKING_CODE=3.0, OVERTIME=0.0, DBLOVERTIME=0.0, TRAVEL=0.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "for field in fields:\n",
    "    df_data_2=df_data_2.withColumn(field,df_data_2[field].cast(\"float\").alias(field))\n",
    "df_data_2=df_data_2.withColumn('ATTRITION',df_data_2['ATTRITION'].cast(\"int\").alias('ATTRITTION'))\n",
    "df_data_2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|ATTRITION|\n",
      "+--------------------+---------+\n",
      "|[1200.0,200.0,182...|        0|\n",
      "|[1200.0,200.0,261...|        0|\n",
      "|[1300.0,320.0,160...|        0|\n",
      "+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va = VectorAssembler(inputCols = fields, outputCol='features')\n",
    "va_df = va.transform(df_data_2)\n",
    "va_df = va_df.select(['features', 'ATTRITION'])\n",
    "va_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtc = GBTClassifier(labelCol=\"ATTRITION\", maxIter=20)\n",
    "\n",
    "pipeline = Pipeline(stages=[va, gbtc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 203\n",
      "Number of testing records : 34\n"
     ]
    }
   ],
   "source": [
    "split_data = df_data_2.randomSplit([0.8, 0.2], 24)\n",
    "train_data = split_data[0]\n",
    "test_data = split_data[1]\n",
    "\n",
    "print(\"Number of training records: \" + str(train_data.count()))\n",
    "print(\"Number of testing records : \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/11/30 05:01:26 INFO : logging results to factsheet for run_id 37d294878159474aa0296df76913ab16\n",
      "2022/11/30 05:01:27 INFO : Successfully logged results to Factsheet service for run_id 37d294878159474aa0296df76913ab16 under asset_id: d2be6bc2-85fb-45a6-a23c-cd11828ac9ea and project_id : a2a29465-a371-4b43-b30a-1ecd79492c0f\n",
      "+-------------+---------------+-----------------+------------+----------------+-----------+---------+-----------------+---------------+-------------+------------+--------+--------+-------------------+---------------+----------+-----------+----------------+---------------------+------------+--------+-----------+------+--------------------+--------------------+--------------------+----------+\n",
      "|POSITION_CODE|DEPARTMENT_CODE|DAYS_WITH_COMPANY|COMMUTE_TIME|AGE_BEGIN_PERIOD|GENDER_CODE|ATTRITION|PERIOD_TOTAL_DAYS|STARTING_SALARY|ENDING_SALARY|NB_INCREASES|   BONUS|NB_BONUS|VACATION_DAYS_TAKEN|SICK_DAYS_TAKEN|PROMOTIONS|NB_MANAGERS|DAYS_IN_POSITION|DAYS_SINCE_LAST_RAISE|RANKING_CODE|OVERTIME|DBLOVERTIME|TRAVEL|            features|       rawPrediction|         probability|prediction|\n",
      "+-------------+---------------+-----------------+------------+----------------+-----------+---------+-----------------+---------------+-------------+------------+--------+--------+-------------------+---------------+----------+-----------+----------------+---------------------+------------+--------+-----------+------+--------------------+--------------------+--------------------+----------+\n",
      "|       1500.0|          300.0|           2035.0|        11.0|            46.0|        0.0|        0|            330.0|      132923.08|    136153.84|         1.0|     0.0|     0.0|               10.0|            9.0|       0.0|        1.0|          2035.0|                210.0|         3.0|     0.0|        0.0|   0.0|[1500.0,300.0,203...|[1.35615356857057...|[0.93774896579379...|       0.0|\n",
      "|       2000.0|          320.0|           1640.0|        15.0|            45.0|        1.0|        0|            330.0|        60000.0|      63500.0|         1.0|  1270.0|     1.0|               15.0|           10.0|       0.0|        1.0|          1640.0|                180.0|         2.0|     0.0|        0.0|   0.0|[2000.0,320.0,164...|[0.95943735199429...|[0.87201289600470...|       0.0|\n",
      "|       2200.0|          320.0|            695.0|         0.0|            29.0|        1.0|        0|            180.0|       23615.38|     23615.38|         0.0|944.6152|     1.0|               22.0|            6.0|       0.0|        1.0|           695.0|                330.0|         3.0|    41.0|    15.0875|   0.0|[2200.0,320.0,695...|[1.35323943594703...|[0.93740786661046...|       0.0|\n",
      "+-------------+---------------+-----------------+------------+----------------+-----------+---------+-----------------+---------------+-------------+------------+--------+--------+-------------------+---------------+----------+-----------+----------------+---------------------+------------+--------+-----------+------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_model = pipeline.fit(train_data)\n",
    "\n",
    "pred = spark_model.transform(test_data)\n",
    "pred.show(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.8524305555555556\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.setLabelCol(\"ATTRITION\")\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(pred, {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing spark model...\n",
      "Note: Warnings!! :  Model type mllib_3.2 is deprecated. We recommend you use a supported model type. See Supported Frameworks https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html\n",
      "Done\n",
      "Model ID: 19e8ace4-5cff-4c9c-bacd-80ddff9f2d76\n"
     ]
    }
   ],
   "source": [
    "print(\"Storing spark model...\")\n",
    "published_model_details = wml_client.repository.store_model(\n",
    "    model=spark_model, \n",
    "    meta_props=model_props,\n",
    "    training_target=['ATTRITION'],\n",
    "    training_data=train_data,\n",
    "    pipeline=pipeline\n",
    ")\n",
    "model_uid = wml_client.repository.get_model_id(published_model_details)\n",
    "\n",
    "print(\"Done\")\n",
    "print(\"Model ID: {}\".format(model_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have completed this notebook. You can now return to the [Data and AI Live Demos lab page](https://cp4d-outcomes.techzone.ibm.com/data-fabric-lab/trusted-ai) and continue with the lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 with Spark",
   "language": "python3",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
